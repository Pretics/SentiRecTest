{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Global Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순서 파악파기\n",
    "\n",
    "python parse_behavior.py --in-file \"$datasetTrainPath/behaviors.tsv\" --out-dir \"$preTrainPath\" --mode train\n",
    "\n",
    "python parse_behavior.py --in-file \"$datasetTestPath/behaviors.tsv\" --out-dir \"$preTestPath\" --mode test --user2int \"$preTrainPath/user2int.tsv\"\n",
    "\n",
    "python parse_news.py --in-file \"$datasetTrainPath/news.tsv\" --out-dir \"$preTrainPath\" --mode train --word-embeddings \"$wordEmbeddingPath/glove.840B.300d.txt\"\n",
    "\n",
    "python parse_news.py --in-file \"$datasetTestPath/news.tsv\" --out-dir \"$preTestPath\" --mode test --word-embeddings \"$wordEmbeddingPath/glove.840B.300d.txt\" --embedding-weights \"$preTrainPath/embedding_weights.csv\" --word2int \"$preTrainPath/word2int.tsv\" --category2int \"$preTrainPath/category2int.tsv\"\n",
    "\n",
    "parse_behavior.py 먼저 진행\n",
    "\n",
    "parse_news는 glove 임베딩 파일 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter notebook에서 import 해서 쓰는 모듈의 코드가 변경될 시, 변동 사항을 자동으로 반영해주는 기능 켜기\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import prep_behavior\n",
    "import prep_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = \"demo\"\n",
    "\n",
    "datasetPath = f\"MIND/{size}\"\n",
    "datasetTrainPath = f\"{datasetPath}/train\"\n",
    "datasetTestPath = f\"{datasetPath}/test\"\n",
    "trainBehaviorsPath = f\"{datasetTrainPath}/behaviors.tsv\"\n",
    "testBehaviorsPath = f\"{datasetTestPath}/behaviors.tsv\"\n",
    "trainNewsPath = f\"{datasetTrainPath}/news.tsv\"\n",
    "testNewsPath = f\"{datasetTestPath}/news.tsv\"\n",
    "wordEmbeddingPath = \"word_embeddings\"\n",
    "\n",
    "processedDataPath = \"processed\"\n",
    "preTrainPath = f\"{processedDataPath}/{size}/train\"\n",
    "preTestPath = f\"{processedDataPath}/{size}/test\"\n",
    "\n",
    "user2int = f\"{preTrainPath}/user2int.tsv\"\n",
    "word2int = f\"{preTrainPath}/word2int.tsv\"\n",
    "category2int = f\"{preTrainPath}/category2int.tsv\"\n",
    "word_embeddings = f\"{wordEmbeddingPath}/glove.840B.300d.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. python parse_behavior.py --in-file \"$datasetTrainPath/behaviors.tsv\" --out-dir \"$preTrainPath\" --mode train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19830/19830 [00:00<00:00, 42982.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing eval data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2204/2204 [00:00<00:00, 56004.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# train behaviors.tsv 전처리\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    in_file = trainBehaviorsPath,\n",
    "    split = 0.1,\n",
    "    out_dir = preTrainPath,\n",
    "    n_negative = 4\n",
    ")\n",
    "\n",
    "os.makedirs(args.out_dir, exist_ok=True)\n",
    "\n",
    "with open(args.in_file, 'r') as trainBehaviors:\n",
    "    behavior = trainBehaviors.readlines()\n",
    "    if (args.split == 0):\n",
    "        prep_behavior.generate_training_data(args, behavior, args.out_dir)\n",
    "    else:\n",
    "        train_behavior, val_behavior = train_test_split(behavior,test_size=args.split, random_state=1234)\n",
    "        user2int = prep_behavior.generate_training_data(args, train_behavior, args.out_dir)\n",
    "        prep_behavior.generate_eval_data(val_behavior, args.out_dir, \"val_behavior.tsv\", user2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. python parse_behavior.py --in-file \"$datasetTestPath/behaviors.tsv\" --out-dir \"$preTestPath\" --mode test --user2int \"$preTrainPath/user2int.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4880/4880 [00:00<00:00, 2146188.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing eval data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7538/7538 [00:00<00:00, 60235.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# test behaviors.tsv 전처리\n",
    "\n",
    "#parse_behavior.py용 args\n",
    "args = argparse.Namespace(\n",
    "    in_file = testBehaviorsPath,\n",
    "    user2int = f\"{preTrainPath}/user2int.tsv\",\n",
    "    out_dir = preTestPath\n",
    ")\n",
    "\n",
    "os.makedirs(args.out_dir, exist_ok=True)\n",
    "\n",
    "user2int = prep_behavior.load_idx_map_as_dict(args.user2int)\n",
    "with open(args.in_file, 'r') as in_file:\n",
    "    behavior = in_file.readlines()\n",
    "    prep_behavior.generate_eval_data(behavior, args.out_dir, \"test_behavior.tsv\", user2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. python parse_news.py --in-file \"$datasetTrainPath/news.tsv\" --out-dir \"$preTrainPath\" --mode train --word-embeddings \"$wordEmbeddingPath/glove.840B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse_news.py용 args\n",
    "args = argparse.Namespace(\n",
    "    in_file = trainNewsPath,\n",
    "    out_dir = preTrainPath,\n",
    "    mode = \"train\",\n",
    "    word_embeddings = word_embeddings,\n",
    "    max_title = 20,\n",
    "    max_abstract = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing/processing word-embeddings\n"
     ]
    }
   ],
   "source": [
    "# prep embedings/vocab\n",
    "embeddings = prep_news.process_word_embeddings(args.word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "2196017\n",
      "<class 'str'>\n",
      "0.25233 0.10176 -0.67485 0.21117 0.43492 0.16542 0.48261 -0.81222 0.041321 0.78502 -0.077857 -0.66324 0.1464 -0.29289 -0.25488 0.019293 -0.20265 0.98232 0.028312 -0.081276 -0.1214 0.13126 -0.17648 0.13556 -0.16361 -0.22574 0.055006 -0.20308 0.20718 0.095785 0.22481 0.21537 -0.32982 -0.12241 -0.40031 -0.079381 -0.19958 -0.015083 -0.079139 -0.18132 0.20681 -0.36196 -0.30744 -0.24422 -0.23113 0.09798 0.1463 -0.062738 0.42934 -0.078038 -0.19627 0.65093 -0.22807 -0.30308 -0.12483 -0.17568 -0.14651 0.15361 -0.29518 0.15099 -0.51726 -0.033564 -0.23109 -0.7833 0.018029 -0.15719 0.02293 0.49639 0.029225 0.05669 0.14616 -0.19195 0.16244 0.23898 0.36431 0.45263 0.2456 0.23803 0.31399 0.3487 -0.035791 0.56108 -0.25345 0.051964 -0.10618 -0.30962 1.0585 -0.42025 0.18216 -0.11256 0.40576 0.11784 -0.19705 -0.075292 0.080723 -0.02782 -0.15617 -0.44681 -0.15165 0.1692 0.098255 -0.031894 0.087143 0.26082 0.002706 0.1319 0.34439 -0.37894 -0.4114 0.081571 -0.11674 -0.43711 0.011144 0.099353 0.26612 0.40025 0.18895 -0.18438 -0.30355 -0.2725 0.22468 -0.40614 0.15618 -0.16043 0.47147 0.0080203 0.56858 0.21934 -0.11181 0.79925 0.10714 -0.50146 0.063593 0.069465 0.15292 -0.2747 -0.20989 0.20737 -0.10681 0.40651 -2.6438 -0.31139 -0.32157 -0.26458 -0.35625 0.070013 -0.18838 0.48773 -0.26167 -0.020805 0.17819 0.15758 -0.13752 0.056464 0.30766 -0.066136 0.4748 -0.27335 0.09732 -0.20832 0.0039332 0.346 -0.08702 -0.54924 -0.18759 -0.17174 0.060324 -0.13521 0.10419 0.30165 0.05798 0.21872 -0.073594 -0.20423 -0.25279 -0.10471 -0.32163 0.12525 -0.31281 0.0097207 -0.26777 -0.61121 -0.11089 -0.13652 0.035135 -0.4939 0.084857 -0.15494 -0.063509 -0.23935 0.28272 0.10849 -0.3365 -0.60764 0.38576 -0.0095438 0.17499 -0.52723 0.62211 0.19544 -0.48977 0.036582 -0.128 -0.016827 0.25647 -0.31698 0.48257 -0.14184 0.11046 -0.3098 -0.63141 -0.37268 0.23183 -0.14268 -0.02341 0.022255 -0.044662 -0.16404 -0.25848 0.1629 0.024751 0.23348 0.27933 0.38998 -0.058968 0.11355 0.15673 0.18583 -0.19814 -0.48123 -0.035084 0.078458 -0.49833 0.10855 -0.20133 0.05292 -0.11583 -0.16009 0.16768 0.42362 -0.23106 0.082465 0.24296 -0.16786 0.0080409 0.085947 0.38033 0.072981 0.1633 0.24704 -0.11094 0.15115 -0.22068 -0.061944 -0.037091 -0.087923 -0.23181 0.15035 -0.19093 -0.19113 -0.11894 0.094908 -0.0043347 0.15362 -0.41201 -0.3073 0.18375 0.40206 -0.0034793 -0.10917 -0.69522 0.10161 -0.079256 0.40329 0.22285 -0.19374 -0.13315 0.073231 0.099832 0.11685 -0.21643 -0.1108 0.10341 0.097286 0.11196 -0.3894 -0.0089363 0.28809 -0.10792 0.028811 0.32545 0.26052 -0.038941 0.075204 0.46031 -0.06293 0.21661 0.17869 -0.51917 0.33591\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(embeddings))\n",
    "print(len(embeddings))\n",
    "print(type(embeddings[\"hello\"]))\n",
    "print(embeddings[\"hello\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing/processing news content\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "  0%|          | 1/26740 [00:00<55:55,  7.97it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "100%|██████████| 26740/26740 [02:16<00:00, 196.62it/s]\n"
     ]
    }
   ],
   "source": [
    "prep_news.prep_news(args, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. python parse_news.py --in-file \"$datasetTestPath/news.tsv\" --out-dir \"$preTestPath\" --mode test --word-embeddings \"$wordEmbeddingPath/glove.840B.300d.txt\" --embedding-weights \"$preTrainPath/embedding_weights.csv\" --word2int \"$preTrainPath/word2int.tsv\" --category2int \"$preTrainPath/category2int.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse_news.py용 args\n",
    "args = argparse.Namespace(\n",
    "    in_file = testNewsPath,\n",
    "    out_dir = preTestPath,\n",
    "    mode = \"test\",\n",
    "    word_embeddings = wordEmbeddingPath,\n",
    "    embedding_weights = f\"{preTrainPath}/embedding_weights.csv\",\n",
    "    word2int = word2int,\n",
    "    category2int = category2int,\n",
    "    max_title = 20,\n",
    "    max_abstract = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing/processing news content\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "100%|██████████| 247/247 [00:00<?, ?it/s]\n",
      "100%|██████████| 41366/41366 [00:00<00:00, 2425035.35it/s]\n",
      "100%|██████████| 41367/41367 [00:00<00:00, 3935531.42it/s]\n",
      "100%|██████████| 18723/18723 [01:39<00:00, 188.66it/s]\n"
     ]
    }
   ],
   "source": [
    "prep_news.prep_news(args, embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newsrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
