{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 출력 확인하기\n",
    "1. 모델 학습/평가 관리용 클래스인 ModelManager의 인스턴스를 생성합니다.\n",
    "2. 학습/평가용으로 불러올 전처리 데이터의 구조는 `BaseDataset` 클래스로 구현됩니다.\n",
    "3. `BaseDataset`은 `torch.utils.data.Dataset` 클래스를 상속받는데, 이를 통해 전처리 데이터를 `DataLoader`로 관리할 수 있게 됩니다.\n",
    "4. `DataLoader`는 `BaseDataset`에 구현된 데이터 구조를 batch data 형태로 바꾸기 위해 데이터의 모든 요소에 차원을 하나 추가합니다.<br/>\n",
    "   -> 상세: `BaseDataset`은 인스턴스 생성 시(즉 __init__함수에서) `list[dict[str, Tensor]]` 형태의 데이터를 생성하고 self.behaviors_parsed에 저장합니다.<br/>\n",
    "   즉 데이터를 하나 뽑으면 `dict[str, Tensor]` 형태의 구조를 갖습니다.<br/>\n",
    "   그런데 mini batch 학습을 위해서는 여러개의 데이터를 하나로 묶어서 batch data를 생성해야 하고, 이 기능을 `DataLoader`로 수행합니다.<br/>\n",
    "   `DataLoader`에서는 여러 데이터를 하나로 묶어 `dict[str, list[Tensor]]` 형태로 변경합니다.<br/>\n",
    "   `list[Tensor]`의 길이는 config파일의 batch_size로 정해집니다.<br/>\n",
    "   여기서 1 epoch의 총 iteration은 behaviors의 총 데이터 수 / batch_size로, 배치 데이터의 총 개수와 같습니다.<br/>\n",
    "5. 모든 모델 클래스가 상속 받는 `pl.LightningModule`의 구현 방식으로 인해, 모델의 인스턴스 자체를 함수처럼 사용하면 해당 클래스에 구현된 forward() 함수가 실행됩니다.\n",
    "6. forward 함수는 학습 시 사용하는 batch data를 받아, behaviors의 사용자 history를 기반으로 해당 사용자의 impression 목록의 click probability를 예측하고 반환합니다.<br/>\n",
    "   -> 상세: behaviors의 모든 데이터는 크게 유저의 history, 해당 유저의 impressions 데이터로 구성됩니다.<br/>\n",
    "   여기서 history는 해당 유저가 과거에 열람한 뉴스 목록, impressions는 이러한 history를 가진 유저에게 특정 시점에 화면에 노출된 뉴스 목록입니다.<br/>\n",
    "   여기서 impressions에는 유저가 해당 뉴스를 클릭했는지(1), 하지 않았는지(0)가 1과 0으로 라벨링 되어있습니다.<br/>\n",
    "   즉 모델이 history만으로 impressions의 모든 뉴스 목록에 대해 해당 history를 가진 유저의 클릭 가능성을 예측하고, 라벨과 비교하거나 순위를 매겨보면 해당 모델이 추천을 얼마나 정확하게 하는지를 계산할 수 있습니다. \n",
    "7. 여기서 반환 형태는 Tensor인데, 내부 데이터는 list[list[float]] 형태입니다. 즉 입력한 모든 batch data에 대한 예측 결과가 반환되는 것입니다.<br/>\n",
    "   -> 상세: 예를 들어 batch_size가 2라면, 각 배치마다 behaviors의 데이터가 2개씩 포함될 것입니다.<br/>\n",
    "    따라서 예측해야할 유저와 impression 쌍도 두개이므로, 반환하는 결과 데이터도 2개입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ckpt 파일로 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nclud\\anaconda3\\envs\\newsrec\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "import sys\n",
    "\n",
    "PROJECT_DIR = path.abspath(path.join(os.getcwd(), \"..\", \"..\"))\n",
    "sys.path.append(PROJECT_DIR)\n",
    "\n",
    "from torch import Tensor\n",
    "from utils.model_manager import ModelManager\n",
    "from utils.base_manager import ManagerArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ManagerArgs(\n",
    "    config_path = path.join(PROJECT_DIR, \"config/model/nrms/exp_demo1.yaml\"),\n",
    "    test_ckpt_path = path.join(PROJECT_DIR, \"logs/lightning_logs/checkpoints/nrms/exp_demo1/epoch=24-val_auc_epoch=0.6996.ckpt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1234\n",
      "100%|██████████| 42561/42561 [00:02<00:00, 16200.33it/s]\n",
      "100%|██████████| 18723/18723 [00:04<00:00, 4135.42it/s]\n",
      "100%|██████████| 7538/7538 [00:09<00:00, 823.61it/s]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NRMS(\n",
       "  (news_encoder): TimeDistributed(\n",
       "    (module): NewsEncoder(\n",
       "      (word_embedding): Embedding(42561, 300, padding_idx=0)\n",
       "      (mh_selfattention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=300, out_features=300, bias=True)\n",
       "      )\n",
       "      (additive_attention): AdditiveAttention(\n",
       "        (linear): Linear(in_features=300, out_features=200, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (user_encoder): UserEncoder(\n",
       "    (mh_selfattention): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=300, out_features=300, bias=True)\n",
       "    )\n",
       "    (additive_attention): AdditiveAttention(\n",
       "      (linear): Linear(in_features=300, out_features=200, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (val_performance_metrics): MetricCollection(\n",
       "    (val_auc): AUC()\n",
       "    (val_mrr): MRR()\n",
       "    (val_ndcg@10): NDCG()\n",
       "    (val_ndcg@5): NDCG()\n",
       "  )\n",
       "  (val_sentiment_diversity_metrics_vader): MetricCollection(\n",
       "    (val_senti@10_vader): Senti()\n",
       "    (val_senti@5_vader): Senti()\n",
       "    (val_senti_mrr_vader): SentiMRR()\n",
       "  )\n",
       "  (val_sentiment_diversity_metrics_bert): MetricCollection(\n",
       "    (val_senti@10_bert): Senti()\n",
       "    (val_senti@5_bert): Senti()\n",
       "    (val_senti_mrr_bert): SentiMRR()\n",
       "  )\n",
       "  (test_performance_metrics): MetricCollection(\n",
       "    (test_auc): AUC()\n",
       "    (test_mrr): MRR()\n",
       "    (test_ndcg@10): NDCG()\n",
       "    (test_ndcg@5): NDCG()\n",
       "  )\n",
       "  (test_sentiment_diversity_metrics_vader): MetricCollection(\n",
       "    (test_senti@10_vader): Senti()\n",
       "    (test_senti@5_vader): Senti()\n",
       "    (test_senti_mrr_vader): SentiMRR()\n",
       "  )\n",
       "  (test_sentiment_diversity_metrics_bert): MetricCollection(\n",
       "    (test_senti@10_bert): Senti()\n",
       "    (test_senti@5_bert): Senti()\n",
       "    (test_senti_mrr_bert): SentiMRR()\n",
       "  )\n",
       "  (test_topic_diversity_metrics): MetricCollection(\n",
       "    (test_topic_div@10): Topic()\n",
       "    (test_topic_div@5): Topic()\n",
       "    (test_topic_mrr): TopicMRR()\n",
       "  )\n",
       "  (test_ils_senti_metrics_vader): MetricCollection(\n",
       "    (test_ils_senti@10_vader): ILS_Senti()\n",
       "    (test_ils_senti@5_vader): ILS_Senti()\n",
       "  )\n",
       "  (test_ils_senti_metrics_bert): MetricCollection(\n",
       "    (test_ils_senti@10_bert): ILS_Senti()\n",
       "    (test_ils_senti@5_bert): ILS_Senti()\n",
       "  )\n",
       "  (test_ils_topic_metrics): MetricCollection(\n",
       "    (test_ils_topic@10): ILS_Topic()\n",
       "    (test_ils_topic@5): ILS_Topic()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_manager = ModelManager(PROJECT_DIR, args, \"test\")\n",
    "model_manager.model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 테스트용 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import itertools\n",
    "\n",
    "def get_batch_from_dataloader(dataloader: DataLoader, index: int):\n",
    "    \"\"\"\n",
    "    DataLoader는 torch.utils.data.Dataset 클래스를 상속받아 정의된 데이터셋의 인스턴스를 받아,\n",
    "    데이터를 설정한 batch size에 맞게 묶어준 뒤 iterator의 형태로 하나씩 뽑아쓸 수 있게 만들어져 있습니다.\n",
    "    따라서 iter(dataloader)로 batch data를 하나씩 뽑아볼 수 있는 iterator를 생성하고,\n",
    "    itertools로 index번째 데이터만 잘라내서 next()로 값을 뽑아내어 반환합니다.\n",
    "    \"\"\"\n",
    "    iterator = iter(dataloader)\n",
    "    item: dict = next(itertools.islice(iterator, index, index + 1))\n",
    "    return item\n",
    "\n",
    "def show_batch_struct(batch_data: dict):\n",
    "    print(type(batch_data))\n",
    "    print(\"{\")\n",
    "    for key in list(batch_data.keys()):\n",
    "        value: Tensor = batch_data[key]\n",
    "        items = value.tolist()\n",
    "        inner_type = type(items[0]).__name__\n",
    "        if inner_type == \"list\":\n",
    "            inner_type = f\"list[{type(items[0][0]).__name__}]\"\n",
    "            if inner_type == \"list[list]\":\n",
    "                inner_type = f\"list[list[{type(items[0][0][0]).__name__}]]\"\n",
    "        print(f\"\\t{key}:\\ttype={type(value).__name__}, shape={tuple(value.shape)}, inner_type={inner_type}\", end=\"\")\n",
    "        if inner_type == int:\n",
    "            print(f\", value:{items[0]}\")\n",
    "        else:\n",
    "            print(\"\")\n",
    "    print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{\n",
      "\tuser:\ttype=Tensor, shape=(1,), inner_type=int\n",
      "\th_title:\ttype=Tensor, shape=(1, 50, 20), inner_type=list[list[int]]\n",
      "\th_abstract:\ttype=Tensor, shape=(1, 50, 50), inner_type=list[list[int]]\n",
      "\th_category:\ttype=Tensor, shape=(1, 50), inner_type=list[int]\n",
      "\th_subcategory:\ttype=Tensor, shape=(1, 50), inner_type=list[int]\n",
      "\th_vader_sentiment:\ttype=Tensor, shape=(1, 50), inner_type=list[float]\n",
      "\th_bert_sentiment:\ttype=Tensor, shape=(1, 50), inner_type=list[float]\n",
      "\thistory_length:\ttype=Tensor, shape=(1,), inner_type=int\n",
      "\tc_title:\ttype=Tensor, shape=(1, 28, 20), inner_type=list[list[int]]\n",
      "\tc_abstract:\ttype=Tensor, shape=(1, 28, 50), inner_type=list[list[int]]\n",
      "\tc_category:\ttype=Tensor, shape=(1, 28), inner_type=list[int]\n",
      "\tc_subcategory:\ttype=Tensor, shape=(1, 28), inner_type=list[int]\n",
      "\tc_vader_sentiment:\ttype=Tensor, shape=(1, 28), inner_type=list[float]\n",
      "\tc_bert_sentiment:\ttype=Tensor, shape=(1, 28), inner_type=list[float]\n",
      "\tlabels:\ttype=Tensor, shape=(1, 28), inner_type=list[int]\n",
      "}\n",
      "{'user': tensor([3677]), 'h_title': tensor([[[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 3298,  2250,  7888,   131, 12180,  4174,  4007,   164,   637,  2609,\n",
      "           2435,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [  817,  1435,   480,    95,   115,  4561,   181,     1,  4120,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 3731,   427,  5215,     5,   443,     5,     8,   597,  2164,     5,\n",
      "           1444,    29, 21775,    11,  7557,    57, 21776,  1799,     0,     0],\n",
      "         [   25,  1655,    45,  5511,  1581, 14754,   151,    29,  3303,     5,\n",
      "             48, 14755,    16,   859,  3338,    57,   357,  8348,     0,     0],\n",
      "         [ 1642,  2986,  1469,    29,  4193,   268,  2743,     5, 13826,   131,\n",
      "           1472,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [    1,  2886,  1946,    24,  6492,  6493,    26,  2310,   131,    65,\n",
      "             26,    71,   273,    37,   376,   644,  1409,   273,     0,     0],\n",
      "         [ 1867,  4630, 24467,  2990,  4721,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 7264,    24,  4383,   893,  1741,   194,    22,  2301,   151,  5485,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [16444,   700,  8327, 16445,    29, 16446,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 7264,    24,  4383,   893,  1741,   194,    22,  2301,   151,  5485,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [  788,   213, 17029,    24,   817,   352,  1552,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 3908,   311,  9372,   164,   250,  2057,   817,  2523,    41,     1,\n",
      "            200,  4120,     5,   126,  2974,    22,  2637,    45,   309,   310],\n",
      "         [ 2218,   358, 15200, 17981,    24,   290,    41,  2223,  2733, 12484,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [14612, 14613,     5,     7, 14614,     5,  8429,  4216,  2831,    61,\n",
      "             26,  2218,  7996,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 4337,   254,  1531,    24,  1552,  4321,   270, 12276,  7343,  7346,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 2257,  2379,  8106,  3610,   164,  1311,   273,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 7011,    26,   352,  1326,   817,  4333,     5,   142,  2815,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [   25,    26,    32,   101,     1,   280,   273,  4472,   729,    46,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [  589, 18535,  4893,  1502,  2622,   101,  1312,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [11131,   646,   131,    64,   509,  8013,    26,  7905,  4118,   925,\n",
      "            597,  4882,   288,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 1428,  3674,  8890,  9525,    26,  2616,   605, 13627,  2679,  2218,\n",
      "           6291, 17505,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 8081,   725,  5930,  4381,   273,  5042,    29,  5876,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [16296,  4127,  4138,  1673,   501,     1, 10836,     8,    31,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [   77,   270, 30448,  1330,    24,  9700,     8,  1253, 20973,    11,\n",
      "            290,  7078,  5418,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 1581,  3306,   757,  1076,  4491,  3648,   164,   446,    29,  2299,\n",
      "           3269,   131,  6607,     5, 18497,   906,     0,     0,     0,     0],\n",
      "         [ 3305,  1949,  4156,    45,  3304,  1837,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [29599,   304, 11670, 15455, 19881,    16,   228,    75, 12446,  9301,\n",
      "           2124,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [   64,     1,   311,    32,     8,    37,  2390,  2218,   151, 24353,\n",
      "           1356,  2584,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 3768,     5,  1552,     5, 15857,  5853,    29,  1471,  1024,  5156,\n",
      "             29,   419,  5259,   101,  3622,  2212,  1857,  7239,    29,  1931],\n",
      "         [  609,   131,   724,    26,   128,  3298,  2250,   824,  6677,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [  173,  3646,  5916,   164,  3585,  5917,  1918,   101,   184,  5918,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [  827,  3067,    37,   664,    22,   910,     5,    86,   865,   198,\n",
      "           9101,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [  946,   824,  6932,    26,   100,  2855,  1116,     1,   100,  2001,\n",
      "             29,   845,  2831,   501,  2977,     0,     0,     0,     0,     0],\n",
      "         [  385,   280,     5,  6425,   132, 12173,   946,   824,  6932,  2855,\n",
      "           1857,  3033,    41,   458,    22,   134,     0,     0,     0,     0],\n",
      "         [25237, 36889,   901, 11166,  7698,  4761,    41,    37,  1146,   164,\n",
      "            270, 36903,  1365,   394,   696,   506,     0,     0,     0,     0],\n",
      "         [ 2218,    26,   311,    57,   290,  5969,    29,   107,  1348, 10655,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 6074,  3262, 22109,  1671, 36241,    24, 13878,    26,  3358,  3418,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 1434,    25,  2074,   480,  9029,    45,    31,  4665,  3823,   330,\n",
      "           1098,    47,  1570,    24,  9171,     0,     0,     0,     0,     0],\n",
      "         [ 7613,   204,  1136,   104,  7096,   273,   131,   310,  1104,   801,\n",
      "            372,  1807,    46,    29, 12290,    24,  1534,  1115,     0,     0]]],\n",
      "       device='cuda:0'), 'h_abstract': tensor([[[    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         ...,\n",
      "         [    1,   782,    26,  ...,     0,     0,     0],\n",
      "         [ 6098,  3613,  1108,  ...,     0,     0,     0],\n",
      "         [38535,  1865,  4126,  ...,     0,     0,     0]]], device='cuda:0'), 'h_category': tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 21, 21,  3,  3,  3,  3,  3,\n",
      "          3, 54,  3, 21, 21,  3, 21,  3,  3, 21,  3,  3, 21,  3,  1,  3,  3,  3,\n",
      "          3,  3, 47,  3, 21,  3, 21, 21, 21, 29, 47, 21,  3, 21]],\n",
      "       device='cuda:0'), 'h_subcategory': tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 124,  22,  88,\n",
      "           4,   4,   4,   4,  23, 128,  23,  22,  22,   4,  26,  88,  88,  22,\n",
      "          23,  88,  56,   4,  38, 116,  88,   4,   4,  88,  94,  74, 124,   4,\n",
      "          22,  56,  56,  33,  94,  56,  23,  22]], device='cuda:0'), 'h_vader_sentiment': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2960,  0.0000, -0.6705,\n",
      "          0.3182, -0.7906, -0.1027,  0.0000, -0.1027, -0.4588,  0.0000,  0.1280,\n",
      "          0.0000,  0.5719, -0.3400,  0.0000, -0.5994,  0.0000, -0.2500, -0.3400,\n",
      "          0.0000,  0.0000,  0.2263,  0.0000,  0.2263,  0.4019, -0.5994, -0.2960,\n",
      "          0.6369, -0.4404,  0.0000,  0.0000,  0.2023, -0.3802, -0.4310, -0.5106,\n",
      "         -0.7783, -0.4019]], device='cuda:0'), 'h_bert_sentiment': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.9965, -0.9741, -0.9886, -0.7961, -0.9090,\n",
      "         -0.9989, -0.9994, -0.9930,  0.9427, -0.9930, -0.9994,  0.2502, -0.9677,\n",
      "          0.8531,  0.9948, -0.9986, -0.4903, -0.9855, -0.9318, -0.9983, -0.9840,\n",
      "          0.9583, -0.9702, -0.9890, -0.8855, -0.9308,  0.9041,  0.9702, -0.9581,\n",
      "          0.9995, -0.9708, -0.9979,  0.5794,  0.9733, -0.9966, -0.9992, -0.9859,\n",
      "         -0.9899, -0.9970]], device='cuda:0'), 'history_length': tensor([50], device='cuda:0'), 'c_title': tensor([[[ 2053,  2283,  1554,  4612,   605,    37,   534,    24,  1147,  2387,\n",
      "            711,    37,  1276, 10890, 19600,     0,     0,     0,     0,     0],\n",
      "         [  383,     8,    77,   301,  4071,   475,   600, 14406,    25,  2148,\n",
      "            164,     1,   560,    45,  1656, 16257,  1399,     0,     0,     0],\n",
      "         [    1, 12627,  2816,  2309,    36,   273,   564,   722,  5408,    29,\n",
      "           3356,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [  660,    74,  3523,  3528,  1471,  3829,   288,  1499,  2266,   164,\n",
      "          15334,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [  512,     8,   910,   131,   525,   250,   118,   726,  5697,  1425,\n",
      "            151,  1143,   483,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [   60,   326,   104,  8308,   501,  4042,   775,   164,    37,   398,\n",
      "              8,  2078,  5539,   486,  9601,    29,    37, 42543,   853,    45],\n",
      "         [   26,  7663,   273,  1425,   131,   704,   151,    86,   910,   288,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [    1,   637,   322,   501,  3103,  1670,    24,     1, 14601,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 1434,  2678,  4349,   280,     5,    61,  2480,  1478, 41673,  2243,\n",
      "             29, 11096,     5,  1472,   476,     0,     0,     0,     0,     0],\n",
      "         [ 1581,   273,   101,  1389, 14773,    57,  2679,  2680,   194,  2678,\n",
      "           5572, 12010,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [  701,   231,   660,    26,  3736, 18075,  6227,   367,   164, 13742,\n",
      "           1276,   409,   273,    29,     1,   419, 30682,     0,     0,     0],\n",
      "         [ 1954,  1955, 16217,  3166,   815,    41,   422, 10773,     5,  3646,\n",
      "           1098,    26,  1289, 20426,   270, 37661,  1365,    29, 22217, 31131],\n",
      "         [    1,  5908,   543,    24,    67,   564,    26,   491,   911,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [   64,  1593, 41466,    57,   251,  2266, 25002,     8,   407,   118,\n",
      "           1407,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 7444, 12291,  1051,    11,  5877,  8953,  1444,  3925,    89,    64,\n",
      "            288,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [12773,  7192, 18768,   164,   100,   595,     5,  7878, 42501,  2598,\n",
      "          10129,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [  120, 11394,   853,   173,  1162,     1,   882,   966,   579,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 2450, 12053,     8,    25,  7963,   311,   883,  8784,   754,   892,\n",
      "           1838,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 4986,  6802,     5, 11196, 11197,   151,   539,     5,   190,    45,\n",
      "           1255, 11388,   273,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [21022,  1564,  5818,  4664,  1775,   859,   115,  9653,    45,  9088,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [  146,   131,  1472,  1926,  1932,    26,  2703,   605,   801,   273,\n",
      "           2480, 35754,   417,   549,    45,  1496,     0,     0,     0,     0],\n",
      "         [ 3005,  2963,   131,   327,  6274,   273,   382,    48,    61,   304,\n",
      "            859,   163, 20719,  1478,     0,     0,     0,     0,     0,     0],\n",
      "         [ 5081,   131,   817,   327,   458,  2051,    89,    45,  5903,    37,\n",
      "           3291,  1800,    57,  5830, 19956,     0,     0,     0,     0,     0],\n",
      "         [ 1398,  6612,  2072,  6651,    26,  1795,    45,  1836,  7652,  2864,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [  667, 19167,  2662,   131,     1,  6380,   884,    41,     1,  1156,\n",
      "             24,     1, 17675, 25081, 41664,  4621,     0,     0,     0,     0],\n",
      "         [ 4127,  3053,   126,  7670,    26,  7108,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 1221,  4744,  3765, 17474, 17824,  5129,   805,  5128,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [   90,    26,    37,   802,    29,     1,   290,   704,   251,   104,\n",
      "             36,  1970, 11116,  2342,  3125,     0,     0,     0,     0,     0]]],\n",
      "       device='cuda:0'), 'c_abstract': tensor([[[3223,  181,   86,  ...,    0,    0,    0],\n",
      "         [ 383,    8,   77,  ...,   22,    0,    0],\n",
      "         [6311,   26, 2816,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 250,    1, 1671,  ...,    0,    0,    0],\n",
      "         [   1, 1221, 3765,  ...,    0,    0,    0],\n",
      "         [   1,  170, 2405,  ...,    0,    0,    0]]], device='cuda:0'), 'c_category': tensor([[ 3,  3, 29,  3, 10,  1, 35, 35, 21,  3, 35, 79, 27, 47,  1, 47, 47,  3,\n",
      "         29,  1, 21, 21, 21,  3, 14,  3,  3,  8]], device='cuda:0'), 'c_subcategory': tensor([[ 88,  88,  33,  88,  44,   6,  36,  36, 124,   4, 120, 122,  28,  48,\n",
      "          38,  94,  68,  23,  33,  81,  22,  26,  22,  23,  15,  23,  74,   9]],\n",
      "       device='cuda:0'), 'c_vader_sentiment': tensor([[-0.4767,  0.0000, -0.5423,  0.0000,  0.4588,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.2263,  0.0000,  0.2023,  0.0000,  0.0000,  0.2023,  0.7964,\n",
      "          0.0000, -0.4215, -0.2732,  0.6369, -0.5994, -0.3612, -0.3612,  0.2732,\n",
      "          0.5106,  0.0000,  0.2263,  0.0000]], device='cuda:0'), 'c_bert_sentiment': tensor([[-0.9898, -0.9620, -0.9962, -0.9962,  0.9984,  0.2318, -0.9719,  0.9990,\n",
      "         -0.9977,  0.9411, -0.9885, -0.9938,  0.9989, -0.9994, -0.9806,  0.9983,\n",
      "         -0.4348, -0.9850, -0.9946,  0.9997, -0.9596, -0.9846, -0.9801, -0.6421,\n",
      "         -0.9767,  0.9658, -0.9818, -0.0486]], device='cuda:0'), 'labels': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "모든 데이터의 첫 번째 차원의 shape 값은 batch size입니다.\n",
    "즉 batch data 안에 실제로 어떤 데이터가 저장되어있는지 알아보기 위해 출력해볼 때\n",
    "해당 값은 별로 의미가 없습니다. \n",
    "\n",
    "예를 들어 h_title의 shape 출력 결과의 각 숫자는 다음과 같은 의미를 지닙니다.\n",
    "(batch_size, config파일에 설정한 max_history 값, 전처리 과정에서 설정한 max_title 값 = 제목의 최대 토큰 개수)\n",
    "\n",
    "c_abstract은 다음과 같습니다.\n",
    "(batch_size, 해당 impressions 데이터에 포함된 뉴스 개수, 전처리 과정에서 설정한 max_abstract 값 = 본문 요약의 최대 토큰 개수)\n",
    "\"\"\"\n",
    "\n",
    "batch_data = get_batch_from_dataloader(model_manager.test_loader, 0)\n",
    "show_batch_struct(batch_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델에 batch data 입력하고 출력 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank     Score    Label \n",
      "--------------------------\n",
      "1       21.96449    0   \n",
      "2       21.63984    0   \n",
      "3       14.37055    0   \n",
      "4       13.39139    0   \n",
      "5       7.60423     0   \n",
      "6       4.49830     0   \n",
      "7       3.25125     0   \n",
      "8       2.46181     0   \n",
      "9       0.83084     0   \n",
      "10      0.31242     0   \n",
      "11      0.16820     0   \n",
      "12      -0.67941    0   \n",
      "13      -3.86770    1   \n",
      "14      -5.43904    0   \n",
      "15      -6.06323    0   \n",
      "16      -8.16475    0   \n",
      "17      -8.50863    0   \n",
      "18      -8.97648    0   \n",
      "19      -9.31507    0   \n",
      "20     -10.63651    0   \n",
      "21     -11.07257    0   \n",
      "22     -12.26732    0   \n",
      "23     -12.92856    0   \n",
      "24     -12.96733    0   \n",
      "25     -13.71577    0   \n",
      "26     -17.14813    0   \n",
      "27     -24.28173    0   \n",
      "28     -29.99214    0   \n"
     ]
    }
   ],
   "source": [
    "def get_result_by_batch(batch_data: dict):\n",
    "    result: Tensor = model_manager.model(batch_data) # model.forward(batch_data) 와 동일하게 동작합니다.\n",
    "    return result\n",
    "\n",
    "def show_result_by_batch(batch_data: dict):\n",
    "    result: Tensor = get_result_by_batch(batch_data)\n",
    "    click_scores = result.tolist()[0]\n",
    "    ranks = []\n",
    "    for index, label in enumerate(batch_data[\"labels\"].tolist()[0]):\n",
    "        ranks.append([label, click_scores[index]])\n",
    "    ranks.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 헤더 출력\n",
    "    print(f\"{'Rank':<6} {'Score':^10} {'Label':^6}\")\n",
    "    print(\"-\" * 26)\n",
    "    # 각 row 출력\n",
    "    for rank, data in enumerate(ranks):\n",
    "        label = data[0]\n",
    "        score = data[1]\n",
    "        print(f\"{rank+1:<6} {score:^10.5f} {label:^6}\")\n",
    "    return result\n",
    "\n",
    "def show_result_by_index(index):\n",
    "    batch_data = get_batch_from_dataloader(model_manager.test_loader, index)\n",
    "    result: Tensor = show_result_by_batch(batch_data)\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "index를 바꿔서 원하는 데이터를 테스트해볼 수 있습니다.\n",
    "\"\"\"\n",
    "result = show_result_by_index(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28])\n",
      "torch.Size([1, 28])\n",
      "[[2.4618093967437744, 0.8308403491973877, -17.148134231567383, -12.928563117980957, -29.992136001586914, -8.508626937866211, -9.315069198608398, -24.281726837158203, 21.96449089050293, -3.8677048683166504, -8.976481437683105, 0.3124237358570099, -12.967334747314453, -12.267322540283203, -11.072565078735352, -10.636513710021973, 0.16820214688777924, 7.604233264923096, -6.063231468200684, -13.715768814086914, 14.370553016662598, 21.63984489440918, 13.391388893127441, 3.2512476444244385, -8.164746284484863, -5.439044952392578, 4.4983038902282715, -0.6794053316116333]]\n"
     ]
    }
   ],
   "source": [
    "print(result.data.shape)\n",
    "print(result.shape)\n",
    "print(result.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# model.forward 가져오기\n",
    "def forward(news_encoder, user_encoder, batch):\n",
    "    # encode candidate news\n",
    "    candidate_news_vector = news_encoder(batch[\"c_title\"])\n",
    "    \n",
    "    # encode history \n",
    "    clicked_news_vector = news_encoder(batch[\"h_title\"])\n",
    "    # encode user\n",
    "    user_vector = user_encoder(clicked_news_vector)\n",
    "    # compute scores for each candidate news\n",
    "    clicks_score = torch.bmm(\n",
    "        candidate_news_vector,\n",
    "        user_vector.unsqueeze(dim=-1)).squeeze(dim=-1)\n",
    "    \n",
    "    return clicks_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.1000, 2.4000, 5.5000, 6.6000, 7.7000])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "tensor([ 6.2000,  0.0000, 11.0000,  0.0000, 15.4000])\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([3.1, 2.4, 5.5, 6.6, 7.7]))\n",
    "print(torch.tensor([3.1, 2.4, 5.5, 6.6, 7.7]).size())\n",
    "print(torch.tensor([3.1, 2.4, 5.5, 6.6, 7.7]).shape)\n",
    "print(F.dropout(torch.tensor([3.1, 2.4, 5.5, 6.6, 7.7]), p=0.5, training=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = nn.Embedding.from_pretrained(\n",
    "    model_manager.pretrained_word_embedding,\n",
    "    freeze=model_manager.config.freeze_word_embeddings,\n",
    "    padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedding(torch.tensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.4618,   0.8308, -17.1481, -12.9286, -29.9921,  -8.5086,  -9.3151,\n",
       "         -24.2817,  21.9645,  -3.8677,  -8.9765,   0.3124, -12.9673, -12.2673,\n",
       "         -11.0726, -10.6365,   0.1682,   7.6042,  -6.0632, -13.7158,  14.3706,\n",
       "          21.6398,  13.3914,   3.2512,  -8.1647,  -5.4390,   4.4983,  -0.6794]],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_encoder = model_manager.model.news_encoder\n",
    "user_encoder = model_manager.model.user_encoder\n",
    "\n",
    "forward(news_encoder, user_encoder, batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode candidate news\n",
    "candidate_news_vector = news_encoder(batch_data[\"c_title\"])\n",
    "\n",
    "# encode history \n",
    "clicked_news_vector = news_encoder(batch_data[\"h_title\"])\n",
    "# encode user\n",
    "user_vector = user_encoder(clicked_news_vector)\n",
    "\n",
    "clicks_score = torch.bmm(\n",
    "        candidate_news_vector,\n",
    "        user_vector.unsqueeze(dim=-1)).squeeze(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 300])\n",
      "torch.Size([1, 50, 300])\n",
      "torch.Size([1, 300])\n",
      "torch.Size([1, 300, 1])\n",
      "torch.Size([1, 28, 1])\n",
      "torch.Size([1, 28])\n"
     ]
    }
   ],
   "source": [
    "print(candidate_news_vector.shape)\n",
    "print(clicked_news_vector.shape)\n",
    "print(user_vector.shape)\n",
    "print(user_vector.unsqueeze(dim=-1).shape)\n",
    "print(torch.bmm(\n",
    "        candidate_news_vector,\n",
    "        user_vector.unsqueeze(dim=-1)).shape)\n",
    "print(clicks_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.4618,   0.8308, -17.1481, -12.9286, -29.9921,  -8.5086,  -9.3151,\n",
       "         -24.2817,  21.9645,  -3.8677,  -8.9765,   0.3124, -12.9673, -12.2673,\n",
       "         -11.0726, -10.6365,   0.1682,   7.6042,  -6.0632, -13.7158,  14.3706,\n",
       "          21.6398,  13.3914,   3.2512,  -8.1647,  -5.4390,   4.4983,  -0.6794]],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(\n",
    "        candidate_news_vector,\n",
    "        user_vector.unsqueeze(dim=-1)).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7264,   24, 4383,  893, 1741,  194,   22, 2301,  151, 5485,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(batch_data['h_title'][0][20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newsrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
